{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tour of ROS tools with examples\n",
    "\n",
    "ROS has plenty of tools that can help prototype, test and deploy robots. \n",
    "\n",
    "We will focus of some of the most important:\n",
    "\n",
    " - Rviz: which is a tool to visialize the state of the robot in 3D as well as to see its sensor readouts\n",
    "\n",
    " - Tf: which is used to simplify calculations of robot's kinematics\n",
    "\n",
    " - Rosbag: which is used to log Robot experiments\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rviz\n",
    "\n",
    "Rviz is a visualization tool for ROS which means that it is very good in understanding standard ROS messagess and parameters and translating them into understandable visualizations. \n",
    "\n",
    "Normally you don't program the Rviz itself but send information to appropriete topics and parameters. You can, however write additional toolboxes for it. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we launch the rviz using the command rosrun rviz rviz\n",
    "import roslaunch\n",
    "\n",
    "import rospy\n",
    "\n",
    "import rosparam\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rospy.init_node(\"tourist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### we will put robot description of Pi Robot (mymodelrobot.appspot.com) to the parameter server\n",
    "\n",
    "with open(\"../../description/pi_robot.urdf\", \"r\") as pi_robot_file:\n",
    "    urdf_text= pi_robot_file.read()\n",
    "\n",
    "\n",
    "rosparam.set_param_raw(\"robot_description\",urdf_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mstarted roslaunch server http://igor-laptop-linux:58642/\u001b[0m\n",
      "\n",
      "SUMMARY\n",
      "========\n",
      "\n",
      "PARAMETERS\n",
      " * /rosdistro: b'indigo\\n'\n",
      " * /rosversion: b'1.11.21\\n'\n",
      "\n",
      "NODES\n",
      "\n",
      "\u001b[1mROS_MASTER_URI=http://igor-laptop-linux:11311\u001b[0m\n",
      "core service [/rosout] found\n"
     ]
    }
   ],
   "source": [
    "### we can now view the robot in rviz\n",
    "\n",
    "launch = roslaunch.scriptapi.ROSLaunch()\n",
    "launch.start()\n",
    "\n",
    "node_rviz = roslaunch.core.Node(\"rviz\",\n",
    "                            \"rviz\", name=\"rviz\") # this starts a ROS Node from ipython_robot_prototyping \n",
    "node_state_publisher= roslaunch.core.Node(\"robot_state_publisher\", \"robot_state_publisher\", name=\"robot_state_publisher\") #this starts our turtle\n",
    "\n",
    "node_joint_publisher = roslaunch.core.Node(\"joint_state_publisher\",\"joint_state_publisher\", name=\"joint_state_publisher\")\n",
    "\n",
    "nodes=[node_rviz,node_state_publisher,node_joint_publisher]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mprocess[rviz-1]: started with pid [24461]\u001b[0m\n",
      "\u001b[1mprocess[robot_state_publisher-2]: started with pid [24462]\u001b[0m\n",
      "\u001b[1mprocess[joint_state_publisher-3]: started with pid [24463]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "### this will start rviz and two helper programs, robot_state publisher and robot_joint_publisher\n",
    "all_procesess=[launch.launch(node) for node in nodes]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above started 3 programs:\n",
    "\n",
    " 1. rviz which is the visualizer\n",
    " 2. robot_state_publisher which takes joint_state messages and using robot design from URDF from \"robot_description\" describes where each robot part should be ( forward kinematics)\n",
    " 3. joint_state_publisher which is a helper node that just publishes that our joints are in 0 position\n",
    " \n",
    "To see our robot in Rviz, you need to click Add and then select \"Robot Model\"\n",
    "\n",
    "![](images/add_robot_rviz.png)\n",
    "\n",
    "Also change the \"fixed frame\" to base_link \n",
    "You should see a Pi robot model in Rviz.\n",
    "\n",
    "Normally we would get the state of the robot -- its joint positions/velocities/ accelerations from its sensors of from a simulation. We can still play around by publishing additional joint state messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_procesess[2].stop() #first we need to stop joint_state_publisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sensor_msgs.msg import JointState\n",
    "from std_msgs.msg import Header\n",
    "\n",
    "pub = rospy.Publisher('joint_states', JointState, queue_size=10)\n",
    "\n",
    "joint_names= ['torso_joint', \n",
    "'head_pan_joint', 'head_tilt_joint', 'left_shoulder_forward_joint',\n",
    "'right_shoulder_forward_joint', 'left_shoulder_up_joint', \n",
    "'right_shoulder_up_joint', 'left_elbow_joint', \n",
    "'right_elbow_joint', 'left_wrist_joint', 'right_wrist_joint']\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "joint_msg = JointState()\n",
    "joint_msg.header = Header()\n",
    "joint_msg.header.stamp = rospy.Time.now()\n",
    "joint_msg.name = joint_names\n",
    "joint_msg.position = [0.5,0,0,0,0,0,0,0,0,0,0]\n",
    "joint_msg.velocity = []\n",
    "joint_msg.effort = []\n",
    "\n",
    "pub.publish(joint_msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This sends new joint position to our robot simulation, moving the torso.\n",
    "\n",
    "We can send such position in a loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def move_torso(angle):\n",
    "    joint_msg = JointState()\n",
    "    joint_msg.header = Header()\n",
    "    joint_msg.header.stamp = rospy.Time.now()\n",
    "    joint_msg.name = joint_names\n",
    "    joint_msg.position = [angle,0,0,0,0,0,0,0,0,0,0]\n",
    "    joint_msg.velocity = []\n",
    "    joint_msg.effort = []\n",
    "\n",
    "    pub.publish(joint_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-c8d2e5752d5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrospy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_sec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mmove_torso\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamplitude\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0momega\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mrate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/ros/indigo/lib/python2.7/dist-packages/rospy/timer.py\u001b[0m in \u001b[0;36msleep\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \"\"\"\n\u001b[1;32m     98\u001b[0m         \u001b[0mcurr_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrospy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrostime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_rostime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_remaining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurr_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_time\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep_dur\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/ros/indigo/lib/python2.7/dist-packages/rospy/timer.py\u001b[0m in \u001b[0;36msleep\u001b[0;34m(duration)\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m             \u001b[0mrospy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrostime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwallsleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mduration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0minitial_rostime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrospy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrostime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_rostime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/ros/indigo/lib/python2.7/dist-packages/rospy/rostime.py\u001b[0m in \u001b[0;36mwallsleep\u001b[0;34m(duration)\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mduration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### we can create a small loop that moves shoulder \n",
    "rate = rospy.Rate(10) # 10Hz move 10 times per s\n",
    "\n",
    "import math\n",
    "\n",
    "### amplitude - how far torso will go\n",
    "### omega - how fast torso will go\n",
    "\n",
    "amplitude= math.pi/2\n",
    "omega= 1.5\n",
    "while not rospy.is_shutdown():\n",
    "        t=rospy.Time.now().to_sec()\n",
    "        move_torso(amplitude*math.sin(omega*t))\n",
    "        rate.sleep()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excercise\n",
    "\n",
    "Try to also move a shoulder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add additional elements to Rviz scene, such as markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from visualization_msgs.msg import Marker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vis_pub = rospy.Publisher(\"visualization_marker\",Marker, queue_size=5 );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "marker = Marker()\n",
    "marker.header.frame_id = \"base_link\";\n",
    "marker.header.stamp = rospy.Time.now()\n",
    "marker.ns = \"markers\";\n",
    "marker.id = 0;\n",
    "marker.type = 2 #sphere\n",
    "marker.action =0 # add\n",
    "marker.pose.position.x = 0.5;\n",
    "marker.pose.position.y = 0.5;\n",
    "marker.pose.position.z =0.5;\n",
    "marker.pose.orientation.x = 0.0;\n",
    "marker.pose.orientation.y = 0.0;\n",
    "marker.pose.orientation.z = 0.0;\n",
    "marker.pose.orientation.w = 1.0;\n",
    "marker.scale.x = 0.1;\n",
    "marker.scale.y = 0.1;\n",
    "marker.scale.z = 0.1;\n",
    "marker.color.a = 1.0; # Don't forget to set the alpha!\n",
    "marker.color.r = 0.0;\n",
    "marker.color.g = 1.0;\n",
    "marker.color.b = 0.0;\n",
    "\n",
    "vis_pub.publish( marker );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see the result in Rviz you need to add new \"Marker\" display type. We can orbit around the robot similarely how you rotated the shoulder.\n",
    "\n",
    "### Excercise\n",
    "\n",
    "Orbit the sphere around the robot\n",
    "\n",
    "HINT: Create a function for x y similar to that\n",
    "\n",
    "x = 0.5 sin( t* omega)\n",
    "\n",
    "y = 0.5 cos (t * omega)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other types of information\n",
    "\n",
    "You can also see other types of information like 3d point clouds or camera streams. We will use usb_camera package to stream our images to ROS.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: cannot launch node of type [cv_camera/cv_camera_node]: cv_camera\n",
      "ROS path [0]=/opt/ros/indigo/share/ros\n",
      "ROS path [1]=/home/igor/catkin_ws/src\n",
      "ROS path [2]=/home/igor/projects/shadow_robot/base/src\n",
      "ROS path [3]=/home/igor/projects/shadow_robot/base_deps/src\n",
      "ROS path [4]=/opt/ros/indigo/share\n",
      "ROS path [5]=/opt/ros/indigo/stacks\u001b[0m\n"
     ]
    },
    {
     "ename": "RLException",
     "evalue": "failed to launch cv_camera/cv_camera_node",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRLException\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-77e439ccbc5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcamera_node\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mroslaunch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cv_camera\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"cv_camera_node\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cv_camera\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#this starts our turtle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcamera_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mall_procesess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcamera_node\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/ros/indigo/lib/python2.7/dist-packages/roslaunch/scriptapi.py\u001b[0m in \u001b[0;36mlaunch\u001b[0;34m(self, node)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mproc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuccess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlaunch_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRLException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"failed to launch %s/%s\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRLException\u001b[0m: failed to launch cv_camera/cv_camera_node"
     ]
    }
   ],
   "source": [
    "camera_node=roslaunch.core.Node(\"cv_camera\", \"cv_camera_node\", name=\"cv_camera\") #this starts our turtle\n",
    "nodes.append(camera_node)\n",
    "all_procesess.append(launch.launch(camera_node))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time you need to add \"Image\" and select topic as \"usb_camera/image_raw\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating forward kinematics is one of most frequent things in robotics.\n",
    "\n",
    "We want to know how each object (say robot) is oriented relative to some other object (say a door handle)\n",
    "so we can then calculate how to move one towards another.\n",
    "\n",
    "Because of that coordinate frames (TF -- transform frames) that describe how elements are related is an important object.\n",
    "\n",
    "Currentely a set of coordinate frames is published for us by robot_state_publisher. Let's read one such frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tf2_msgs.msg import TFMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transforms: \n",
      "  - \n",
      "    header: \n",
      "      seq: 0\n",
      "      stamp: \n",
      "        secs: 1502820842\n",
      "        nsecs: 302270720\n",
      "      frame_id: head_link\n",
      "    child_frame_id: antenna_link\n",
      "    transform: \n",
      "      translation: \n",
      "        x: 0.0\n",
      "        y: -0.025\n",
      "        z: 0.065\n",
      "      rotation: \n",
      "        x: 0.0\n",
      "        y: 0.0\n",
      "        z: 0.0\n",
      "        w: 1.0\n",
      "  - \n",
      "    header: \n",
      "      seq: 0\n",
      "      stamp: \n",
      "        secs: 1502820842\n",
      "        nsecs: 302280984\n",
      "      frame_id: base_link\n",
      "    child_frame_id: base_laser\n",
      "    transform: \n",
      "      translation: \n",
      "        x: 0.18\n",
      "        y: 0.0\n",
      "        z: 0.07\n",
      "      rotation: \n",
      "        x: 0.0\n",
      "        y: 0.0\n",
      "        z: 0.0\n",
      "        w: 1.0\n",
      "  - \n",
      "    header: \n",
      "      seq: 0\n",
      "      stamp: \n",
      "        secs: 1502820842\n",
      "        nsecs: 302283957\n",
      "      frame_id: base_link\n",
      "    child_frame_id: cpu_link\n",
      "    transform: \n",
      "      translation: \n",
      "        x: 0.025\n",
      "        y: 0.0\n",
      "        z: 0.085\n",
      "      rotation: \n",
      "        x: 0.0\n",
      "        y: 0.0\n",
      "        z: 0.0\n",
      "        w: 1.0\n",
      "  - \n",
      "    header: \n",
      "      seq: 0\n",
      "      stamp: \n",
      "        secs: 1502820842\n",
      "        nsecs: 302287151\n",
      "      frame_id: torso_link\n",
      "    child_frame_id: head_pan_link\n",
      "    transform: \n",
      "      translation: \n",
      "        x: 0.0\n",
      "        y: 0.0\n",
      "        z: 0.225\n",
      "      rotation: \n",
      "        x: 0.0\n",
      "        y: 0.0\n",
      "        z: 0.0\n",
      "        w: 1.0\n",
      "  - \n",
      "    header: \n",
      "      seq: 0\n",
      "      stamp: \n",
      "        secs: 1502820842\n",
      "        nsecs: 302288414\n",
      "      frame_id: left_wrist_link\n",
      "    child_frame_id: left_hand_link\n",
      "    transform: \n",
      "      translation: \n",
      "        x: 0.0\n",
      "        y: 0.0\n",
      "        z: -0.055\n",
      "      rotation: \n",
      "        x: 0.0\n",
      "        y: 0.0\n",
      "        z: 0.0\n",
      "        w: 1.0\n",
      "  - \n",
      "    header: \n",
      "      seq: 0\n",
      "      stamp: \n",
      "        secs: 1502820842\n",
      "        nsecs: 302292466\n",
      "      frame_id: left_elbow_link\n",
      "    child_frame_id: left_lower_arm_link\n",
      "    transform: \n",
      "      translation: \n",
      "        x: 0.0\n",
      "        y: 0.0\n",
      "        z: -0.08\n",
      "      rotation: \n",
      "        x: 0.0\n",
      "        y: 0.0\n",
      "        z: 0.0\n",
      "        w: 1.0\n",
      "  - \n",
      "    header: \n",
      "      seq: 0\n",
      "      stamp: \n",
      "        secs: 1502820842\n",
      "        nsecs: 302293994\n",
      "      frame_id: torso_link\n",
      "    child_frame_id: left_shoulder_link\n",
      "    transform: \n",
      "      translation: \n",
      "        x: 0.0\n",
      "        y: 0.055\n",
      "        z: 0.165\n",
      "      rotation: \n",
      "        x: 0.0\n",
      "        y: 0.0\n",
      "        z: 0.0\n",
      "        w: 1.0\n",
      "  - \n",
      "    header: \n",
      "      seq: 0\n",
      "      stamp: \n",
      "        secs: 1502820842\n",
      "        nsecs: 302295493\n",
      "      frame_id: left_shoulder_up_link\n",
      "    child_frame_id: left_upper_arm_link\n",
      "    transform: \n",
      "      translation: \n",
      "        x: 0.0\n",
      "        y: 0.0\n",
      "        z: -0.05\n",
      "      rotation: \n",
      "        x: 0.0\n",
      "        y: 0.0\n",
      "        z: 0.0\n",
      "        w: 1.0\n",
      "  - \n",
      "    header: \n",
      "      seq: 0\n",
      "      stamp: \n",
      "        secs: 1502820842\n",
      "        nsecs: 302296763\n",
      "      frame_id: neck_link\n",
      "    child_frame_id: head_link\n",
      "    transform: \n",
      "      translation: \n",
      "        x: 0.05\n",
      "        y: 0.0\n",
      "        z: 0.015\n",
      "      rotation: \n",
      "        x: 0.0\n",
      "        y: 0.0\n",
      "        z: 0.0\n",
      "        w: 1.0\n",
      "  - \n",
      "    header: \n",
      "      seq: 0\n",
      "      stamp: \n",
      "        secs: 1502820842\n",
      "        nsecs: 302302694\n",
      "      frame_id: right_wrist_link\n",
      "    child_frame_id: right_hand_link\n",
      "    transform: \n",
      "      translation: \n",
      "        x: 0.0\n",
      "        y: 0.0\n",
      "        z: -0.055\n",
      "      rotation: \n",
      "        x: 0.0\n",
      "        y: 0.0\n",
      "        z: 0.0\n",
      "        w: 1.0\n",
      "  - \n",
      "    header: \n",
      "      seq: 0\n",
      "      stamp: \n",
      "        secs: 1502820842\n",
      "        nsecs: 302304344\n",
      "      frame_id: right_elbow_link\n",
      "    child_frame_id: right_lower_arm_link\n",
      "    transform: \n",
      "      translation: \n",
      "        x: 0.0\n",
      "        y: 0.0\n",
      "        z: -0.08\n",
      "      rotation: \n",
      "        x: 0.0\n",
      "        y: 0.0\n",
      "        z: 0.0\n",
      "        w: 1.0\n",
      "  - \n",
      "    header: \n",
      "      seq: 0\n",
      "      stamp: \n",
      "        secs: 1502820842\n",
      "        nsecs: 302305877\n",
      "      frame_id: torso_link\n",
      "    child_frame_id: right_shoulder_link\n",
      "    transform: \n",
      "      translation: \n",
      "        x: 0.0\n",
      "        y: -0.055\n",
      "        z: 0.165\n",
      "      rotation: \n",
      "        x: 0.0\n",
      "        y: 0.0\n",
      "        z: 0.0\n",
      "        w: 1.0\n",
      "  - \n",
      "    header: \n",
      "      seq: 0\n",
      "      stamp: \n",
      "        secs: 1502820842\n",
      "        nsecs: 302307154\n",
      "      frame_id: right_shoulder_up_link\n",
      "    child_frame_id: right_upper_arm_link\n",
      "    transform: \n",
      "      translation: \n",
      "        x: 0.0\n",
      "        y: 0.0\n",
      "        z: -0.05\n",
      "      rotation: \n",
      "        x: 0.0\n",
      "        y: 0.0\n",
      "        z: 0.0\n",
      "        w: 1.0\n",
      "  - \n",
      "    header: \n",
      "      seq: 0\n",
      "      stamp: \n",
      "        secs: 1502820842\n",
      "        nsecs: 302308387\n",
      "      frame_id: cpu_link\n",
      "    child_frame_id: upper_base_link\n",
      "    transform: \n",
      "      translation: \n",
      "        x: 0.0\n",
      "        y: 0.0\n",
      "        z: 0.07\n",
      "      rotation: \n",
      "        x: 0.0\n",
      "        y: 0.0\n",
      "        z: 0.0\n",
      "        w: 1.0\n"
     ]
    }
   ],
   "source": [
    "tf_message=rospy.wait_for_message(\"/tf\",TFMessage)\n",
    "print(tf_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usuall, there is a lot of info in such a single message. But the important part are two:\n",
    "one is the child - parent relation between frame_id and child_frame_id. \n",
    "\n",
    "/tf topic has messages that are *relations* between some coordinate systems. In can be realition between a ground and a robot but it can be a relation between a robot torso and a robot shoulder. To build a whole robot structure we collect a set of such relations to build a *kinematic tree*.\n",
    "\n",
    "Let's see how this kinematic tree looks for our robot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening to /tf for 5.000000 seconds\n",
      "Done Listening\n",
      "dot - graphviz version 2.36.0 (20140111.2315)\n",
      "\n",
      "Detected dot version 2.36\n",
      "frames.pdf generated\n"
     ]
    }
   ],
   "source": [
    "!rosrun tf view_frames && evince frames.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "But actually we normally do not use these messagages directely, instead we use tf.TransformListener'ers (instead of Subscribers) and tf.TransformBroadcaster's. This is  because we can select some particular transformations that we need and the listener will calculate them for us. \n",
    "\n",
    "For example, let's say we want to know the position of robot's head relative to its base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "move_torso(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "\"torso_link\" passed to lookupTransform argument target_frame does not exist. \n",
      "fufuf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<stdin>\", line 22, in <module>\n",
      "NameError: name 'trans' is not defined\n"
     ]
    }
   ],
   "source": [
    "%%python2\n",
    "\n",
    "\n",
    "import tf\n",
    "import rospy\n",
    "## here we just move robot to some base position\n",
    "\n",
    "rospy.init_node('turtle_tf_listener')\n",
    "\n",
    "listener = tf.TransformListener()\n",
    "\n",
    "\n",
    "print(\"test\")\n",
    "rate = rospy.Rate(10.0)\n",
    "\n",
    "try:\n",
    "\n",
    "        (trans,rot) = listener.lookupTransform( '/torso_link','right_shoulder_link', rospy.Time(0))\n",
    "except (tf.LookupException, tf.ConnectivityException, tf.ExtrapolationException) as e:\n",
    "        print(e)\n",
    "        print(\"fufuf\")\n",
    "        \n",
    "print(trans)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trans' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-104727d760d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'trans' is not defined"
     ]
    }
   ],
   "source": [
    "trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
